{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb4f94d4",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing (Descriptors + Fingerprints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8630e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from rdkit import Chem, RDLogger, DataStructs\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors, AllChem, MACCSkeys\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors as md\n",
    "from morfeus import XTB\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    RepeatedStratifiedKFold,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    RandomizedSearchCV,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import shap\n",
    "import optuna\n",
    "from pyscf import gto, scf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6815b2a",
   "metadata": {},
   "source": [
    "## Molecule, Descriptor + Fingerprints and Outlier Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8c03568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def molecule_from_smiles(smiles):\n",
    "    lg = RDLogger.logger()\n",
    "    # Temporarily silence RDKit logs\n",
    "    lg.setLevel(RDLogger.CRITICAL)\n",
    "    try:\n",
    "        # Extract molecule\n",
    "        molecule = Chem.MolFromSmiles(smiles, sanitize=True)\n",
    "        if molecule is None:\n",
    "            return None, \"failed\"\n",
    "\n",
    "        # Remove salts\n",
    "        clean_molecule = rdMolStandardize.LargestFragmentChooser()\n",
    "        molecule = clean_molecule.choose(molecule)\n",
    "\n",
    "        # Sanitize molecule again to reflect changes\n",
    "        Chem.SanitizeMol(molecule)\n",
    "        return molecule, \"succeed\"\n",
    "    except Exception as e:\n",
    "        return None, f\"error: {e}\"\n",
    "    finally:\n",
    "        # Re-enable logging afterward\n",
    "        lg.setLevel(RDLogger.INFO)\n",
    "\n",
    "\n",
    "def calculate_descriptors(molecule):\n",
    "    # Get all descriptors (1D/2D)\n",
    "    descriptor_names = []\n",
    "    for descriptor, _ in Descriptors._descList:\n",
    "        descriptor_names.append(descriptor)\n",
    "\n",
    "    # Use descriptors to calculate values\n",
    "    calculator = md.MolecularDescriptorCalculator(descriptor_names)\n",
    "    descriptor_values = calculator.CalcDescriptors(molecule)\n",
    "\n",
    "    # Create dictionary\n",
    "    descriptors = dict(zip(descriptor_names, descriptor_values))\n",
    "    return descriptors\n",
    "\n",
    "\n",
    "def compute_iqr_limits(df, factor=1.5):\n",
    "    # Calculate IQR limits\n",
    "    limits = {}\n",
    "    for col in df.columns:\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        # If IQR is 0 - column is too flat - skip\n",
    "        if iqr == 0 or np.isnan(iqr):\n",
    "            continue\n",
    "\n",
    "        lower = q1 - factor * iqr\n",
    "        upper = q3 + factor * iqr\n",
    "        limits[col] = (lower, upper)\n",
    "    return limits\n",
    "\n",
    "\n",
    "def apply_iqr_limits(df, limits):\n",
    "    # Apply the limits\n",
    "    df_clipped = df.copy()\n",
    "    for col, (lower, upper) in limits.items():\n",
    "        df_clipped[col] = df_clipped[col].clip(lower, upper)\n",
    "    return df_clipped\n",
    "\n",
    "\n",
    "def bitvect_to_dict(fp, prefix):\n",
    "    # Convert bit vector to dictionary (create features)\n",
    "    n_bits = fp.GetNumBits()\n",
    "    arr = np.zeros((n_bits,), dtype=int)\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    features = {}\n",
    "    for i, v in enumerate(arr):\n",
    "        features[f\"{prefix}_{i}\"] = int(v)\n",
    "    return features\n",
    "\n",
    "\n",
    "def calculate_fingerprints(mol):\n",
    "    RDLogger.DisableLog(\"rdApp.*\")\n",
    "    # Calculate Morgan, RDKit, MACCS, AtomPair and Topological Torsion fingerprint\n",
    "    feats = {}\n",
    "    if mol is None:\n",
    "        return feats\n",
    "\n",
    "    # Morgan (ECFP) fingerprint\n",
    "    morgan_bits = 2048\n",
    "    morgan_radius = 2\n",
    "    fp_morgan = rdMolDescriptors.GetMorganFingerprintAsBitVect(\n",
    "        mol, radius=morgan_radius, nBits=morgan_bits\n",
    "    )\n",
    "    feats.update(bitvect_to_dict(fp_morgan, f\"Morgan{morgan_radius}_{morgan_bits}\"))\n",
    "\n",
    "    # RDKit topological fingerprint\n",
    "    rdk_bits = 2048\n",
    "    fp_rdk = Chem.RDKFingerprint(mol, fpSize=rdk_bits)\n",
    "    feats.update(bitvect_to_dict(fp_rdk, f\"RDK_{rdk_bits}\"))\n",
    "\n",
    "    # MACCS keys (167 bits)\n",
    "    fp_maccs = MACCSkeys.GenMACCSKeys(mol)\n",
    "    feats.update(bitvect_to_dict(fp_maccs, \"MACCS\"))\n",
    "\n",
    "    # AtomPair fingerprint\n",
    "    ap_bits = 2048\n",
    "    fp_ap = rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(mol, nBits=ap_bits)\n",
    "    feats.update(bitvect_to_dict(fp_ap, f\"AtomPair_{ap_bits}\"))\n",
    "\n",
    "    # Topological torsion fingerprint\n",
    "    tt_bits = 2048\n",
    "    fp_tt = rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(\n",
    "        mol, nBits=tt_bits\n",
    "    )\n",
    "    feats.update(bitvect_to_dict(fp_tt, f\"Torsion_{tt_bits}\"))\n",
    "\n",
    "    RDLogger.EnableLog(\"rdApp.*\")\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "def prepare_3d_molecule(mol):\n",
    "    # Create 3D molecule\n",
    "    if mol is None:\n",
    "        return None\n",
    "\n",
    "    mol3d = Chem.AddHs(mol)\n",
    "\n",
    "    try:\n",
    "        # Calculate 3D coordinates and energy\n",
    "        AllChem.EmbedMolecule(mol3d, AllChem.ETKDG())\n",
    "        AllChem.UFFOptimizeMolecule(mol3d, maxIters=200)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    return mol3d\n",
    "\n",
    "\n",
    "def infer_charge_and_unpaired(mol):\n",
    "    \"\"\"\n",
    "    Infer total charge and number of unpaired electrons from RDKit.\n",
    "    Good enough for typical organic molecules.\n",
    "    \"\"\"\n",
    "    total_charge = sum(a.GetFormalCharge() for a in mol.GetAtoms())\n",
    "    n_unpaired = sum(a.GetNumRadicalElectrons() for a in mol.GetAtoms())\n",
    "    return total_charge, n_unpaired\n",
    "\n",
    "\n",
    "def compute_homo_lumo_xtb(mol):\n",
    "    \"\"\"\n",
    "    Fast HOMO/LUMO computation using GFN2-xTB via morfeus.XTB.\n",
    "\n",
    "    Returns the same keys as the old PySCF version:\n",
    "        - HOMO_eV\n",
    "        - LUMO_eV\n",
    "        - HL_Gap_eV\n",
    "    \"\"\"\n",
    "    feats = {\n",
    "        \"HOMO_eV\": np.nan,\n",
    "        \"LUMO_eV\": np.nan,\n",
    "        \"HL_Gap_eV\": np.nan,\n",
    "    }\n",
    "\n",
    "    if mol is None:\n",
    "        return feats\n",
    "\n",
    "    # Create 3D molecule (reuses your existing pipeline)\n",
    "    mol3d = prepare_3d_molecule(mol)\n",
    "    if mol3d is None:\n",
    "        return feats\n",
    "\n",
    "    # Extract elements and coordinates\n",
    "    conf = mol3d.GetConformer()\n",
    "    elements = []\n",
    "    coords = []\n",
    "    for atom in mol3d.GetAtoms():\n",
    "        pos = conf.GetAtomPosition(atom.GetIdx())\n",
    "        elements.append(atom.GetSymbol())\n",
    "        coords.append([pos.x, pos.y, pos.z])\n",
    "    coords = np.array(coords, dtype=float)  # Ã…\n",
    "\n",
    "    charge, n_unpaired = infer_charge_and_unpaired(mol3d)\n",
    "\n",
    "    try:\n",
    "        # method=2 -> GFN2-xTB\n",
    "        xtb_calc = XTB(\n",
    "            elements=elements,\n",
    "            coordinates=coords,\n",
    "            method=2,\n",
    "            charge=charge,\n",
    "            n_unpaired=n_unpaired,\n",
    "        )\n",
    "\n",
    "        feats[\"HOMO_eV\"] = xtb_calc.get_homo(unit=\"eV\")\n",
    "        feats[\"LUMO_eV\"] = xtb_calc.get_lumo(unit=\"eV\")\n",
    "        feats[\"HL_Gap_eV\"] = xtb_calc.get_homo_lumo_gap(unit=\"eV\")\n",
    "\n",
    "    except Exception:\n",
    "        # keep NaNs if xtb fails\n",
    "        pass\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3bbfdb",
   "metadata": {},
   "source": [
    "## Dataset Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f95b75c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'in_vitro_3T3_in_chemico_dataset.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m CORRELATION_THRESHOLD = \u001b[32m0.65\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Load dataset and skip first row (Header)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m dataset = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mORIG_DATASET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopenpyxl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSKIP_ROWS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m descriptor_rows = []\n\u001b[32m     24\u001b[39m state_molecules = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/toxipred/lib/python3.11/site-packages/pandas/io/excel/_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/toxipred/lib/python3.11/site-packages/pandas/io/excel/_base.py:1567\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28mself\u001b[39m.engine = engine\n\u001b[32m   1565\u001b[39m \u001b[38;5;28mself\u001b[39m.storage_options = storage_options\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1571\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/toxipred/lib/python3.11/site-packages/pandas/io/excel/_openpyxl.py:553\u001b[39m, in \u001b[36mOpenpyxlReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    541\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    542\u001b[39m \u001b[33;03mReader using openpyxl engine.\u001b[39;00m\n\u001b[32m    543\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    550\u001b[39m \u001b[33;03m    Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[32m    551\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    552\u001b[39m import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mopenpyxl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/toxipred/lib/python3.11/site-packages/pandas/io/excel/_base.py:563\u001b[39m, in \u001b[36mBaseExcelReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = IOHandles(\n\u001b[32m    560\u001b[39m     handle=filepath_or_buffer, compression={\u001b[33m\"\u001b[39m\u001b[33mmethod\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[32m    561\u001b[39m )\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, (ExcelFile, \u001b[38;5;28mself\u001b[39m._workbook_class)):\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.handles.handle, \u001b[38;5;28mself\u001b[39m._workbook_class):\n\u001b[32m    568\u001b[39m     \u001b[38;5;28mself\u001b[39m.book = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/toxipred/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'in_vitro_3T3_in_chemico_dataset.xlsx'"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "ORIG_DATASET = \"in_vitro_3T3_in_chemico_dataset.xlsx\"\n",
    "SKIP_ROWS = 1\n",
    "SMILES_COL = \"SMILES code\"\n",
    "TARGET_COL = \"Phototoxicity\"\n",
    "FULL_OUTPUT_DATASET = (\n",
    "    \"processed_datasets/in_vitro_3T3_in_chemico_dataset_homolumo_processed.xlsx\"\n",
    ")\n",
    "# Outputs\n",
    "TRAIN_X_CSV = \"processed_datasets/in_vitro_3T3_in_chemico_homolumo_x_train.csv\"\n",
    "TEST_X_CSV = \"processed_datasets/in_vitro_3T3_in_chemico_homolumo_x_test.csv\"\n",
    "TRAIN_Y_CSV = \"processed_datasets/in_vitro_3T3_in_chemico_homolumo_y_train.csv\"\n",
    "TEST_Y_CSV = \"processed_datasets/in_vitro_3T3_in_chemico_homolumo_y_test.csv\"\n",
    "\n",
    "# Near constant threshold - tolerance\n",
    "SIMILARITY_THRESHOLD = 0.7\n",
    "# Correlation threshold\n",
    "CORRELATION_THRESHOLD = 0.65\n",
    "\n",
    "# Load dataset and skip first row (Header)\n",
    "dataset = pd.read_excel(ORIG_DATASET, engine=\"openpyxl\", skiprows=SKIP_ROWS)\n",
    "\n",
    "descriptor_rows = []\n",
    "state_molecules = []\n",
    "molecules = []\n",
    "\n",
    "for smiles in dataset[SMILES_COL].astype(str):\n",
    "    molecule, state = molecule_from_smiles(smiles)\n",
    "    state_molecules.append(state)\n",
    "    molecules.append(molecule)\n",
    "\n",
    "    if molecule is None:\n",
    "        descriptor_rows.append({})\n",
    "        continue\n",
    "\n",
    "    # 1D/2D RDKit descriptors\n",
    "    desc_feats = calculate_descriptors(molecule)\n",
    "\n",
    "    # Fingerprints\n",
    "    fp_feats = calculate_fingerprints(molecule)\n",
    "\n",
    "    # HOMO / LUMO / gap from PySCF\n",
    "    homo_lumo_feats = compute_homo_lumo_xtb(molecule)\n",
    "\n",
    "    # Merge all feature dicts\n",
    "    # all_feats = {**desc_feats, **fp_feats, **homo_lumo_feats}\n",
    "    all_feats = {**homo_lumo_feats}\n",
    "    descriptor_rows.append(all_feats)\n",
    "\n",
    "# Convert list of dictionaries into dataframe\n",
    "descriptor_data_all = pd.DataFrame(descriptor_rows)\n",
    "\n",
    "# Keep everything + status\n",
    "output = pd.concat(\n",
    "    [dataset.reset_index(drop=True), descriptor_data_all.reset_index(drop=True)], axis=1\n",
    ")\n",
    "output[\"MoleculeStatus\"] = state_molecules\n",
    "\n",
    "# Output whole dataset with descriptors and state\n",
    "with pd.ExcelWriter(FULL_OUTPUT_DATASET, engine=\"openpyxl\") as writer:\n",
    "    output.to_excel(writer, index=False, sheet_name=\"Descriptors\")\n",
    "\n",
    "print(f\"Full - Rows: {len(output)}/Columns: {output.shape[1]}\")\n",
    "print(output.head().to_string(index=False))\n",
    "\n",
    "# # Drop failed molecules - boolean array\n",
    "# molecules_right = []\n",
    "# for molecule in molecules:\n",
    "#     if molecule is not None:\n",
    "#         molecules_right.append(True)\n",
    "#     else:\n",
    "#         molecules_right.append(False)\n",
    "# if not any(molecules_right):\n",
    "#     raise ValueError(\"No valid molecules after SMILES parsing.\")\n",
    "\n",
    "# dataset_ok = dataset.loc[molecules_right].reset_index(drop=True)\n",
    "# descriptor_ok = descriptor_data_all.loc[molecules_right].reset_index(drop=True)\n",
    "\n",
    "# # Target\n",
    "# y_full = dataset_ok[TARGET_COL].astype(int)\n",
    "\n",
    "# # Take only numeric descriptor columns\n",
    "# X_full = descriptor_ok.select_dtypes(include=[np.number]).copy()\n",
    "# for column in X_full.columns:\n",
    "#     X_full[column] = X_full[column].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# # Drop columns that are entirely NaN\n",
    "# all_nan_cols = X_full.columns[X_full.isna().all()].tolist()\n",
    "# if all_nan_cols:\n",
    "#     print(f\"Dropping {len(all_nan_cols)} NaN columns.\")\n",
    "#     X_full = X_full.drop(columns=all_nan_cols)\n",
    "\n",
    "# # Split dataset - train and test\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X_full, y_full, test_size=0.2, random_state=42, stratify=y_full\n",
    "# )\n",
    "\n",
    "# # Calculate medians for each column in train only\n",
    "# train_medians = X_train.median(numeric_only=True)\n",
    "\n",
    "# # Fill missing values in both train and test using those medians\n",
    "# X_train = X_train.fillna(train_medians)\n",
    "# X_test = X_test.fillna(train_medians)\n",
    "\n",
    "# # Compute constants on train only\n",
    "# constant_cols = []\n",
    "# for col in X_train.columns:\n",
    "#     top_freq = X_train[col].value_counts(normalize=True, dropna=False).max()\n",
    "#     if top_freq >= SIMILARITY_THRESHOLD:\n",
    "#         constant_cols.append(col)\n",
    "\n",
    "# # Drop from train and apply same drop to test\n",
    "# if constant_cols:\n",
    "#     X_train = X_train.drop(columns=constant_cols)\n",
    "#     X_test = X_test.drop(columns=constant_cols)\n",
    "#     print(f\"Dropped {len(constant_cols)} constant/almost-constant columns.\")\n",
    "\n",
    "# # Compute absolute correlation matrix on training data\n",
    "# corr_matrix = X_train.corr().abs()\n",
    "# # Keep only upper triangle of the matrix\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "# # Find columns to drop - correlation\n",
    "# high_corr_cols = []\n",
    "# for col in upper.columns:\n",
    "#     if any(upper[col] > CORRELATION_THRESHOLD):\n",
    "#         high_corr_cols.append(col)\n",
    "\n",
    "# # Drop from both train and test\n",
    "# if high_corr_cols:\n",
    "#     X_train = X_train.drop(columns=high_corr_cols)\n",
    "#     X_test = X_test.drop(columns=high_corr_cols)\n",
    "#     print(f\"Dropped {len(high_corr_cols)} highly correlated columns.\")\n",
    "\n",
    "# # Compute IQR limits on training data\n",
    "# iqr_limits = compute_iqr_limits(X_train, factor=1.5)\n",
    "\n",
    "# # Apply limits to both train and test sets\n",
    "# X_train = apply_iqr_limits(X_train, iqr_limits)\n",
    "# X_test = apply_iqr_limits(X_test, iqr_limits)\n",
    "\n",
    "# # Scaling not necessary for all models\n",
    "# # Splitting the dataset to Fingerprint and Descriptor sets\n",
    "# FP_PREFIXES = (\n",
    "#     \"Morgan\",\n",
    "#     \"RDK_\",\n",
    "#     \"MACCS\",\n",
    "#     \"AtomPair_\",\n",
    "#     \"Torsion_\",\n",
    "# )  # Identify fingerprint columns by prefix\n",
    "# fp_cols = [c for c in X_train.columns if c.startswith(FP_PREFIXES)]\n",
    "# desc_cols = [c for c in X_train.columns if c not in fp_cols]\n",
    "\n",
    "# print(f\"Descriptor columns: {len(desc_cols)}, fingerprint columns: {len(fp_cols)}\")\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# if desc_cols:\n",
    "#     X_train_desc_scaled = scaler.fit_transform(X_train[desc_cols])\n",
    "#     X_test_desc_scaled = scaler.transform(X_test[desc_cols])\n",
    "\n",
    "#     # Start from copies so we keep original indexing and all columns\n",
    "#     X_train_scaled = X_train.copy()\n",
    "#     X_test_scaled = X_test.copy()\n",
    "\n",
    "#     # Overwrite only descriptor columns with scaled values\n",
    "#     X_train_scaled[desc_cols] = X_train_desc_scaled\n",
    "#     X_test_scaled[desc_cols] = X_test_desc_scaled\n",
    "# else:\n",
    "#     X_train_scaled = X_train.copy()\n",
    "#     X_test_scaled = X_test.copy()\n",
    "\n",
    "# X_train = X_train_scaled\n",
    "# X_test = X_test_scaled\n",
    "\n",
    "# # Save processed datasets\n",
    "# X_train.to_csv(TRAIN_X_CSV, index=False)\n",
    "# X_test.to_csv(TEST_X_CSV, index=False)\n",
    "# y_train.to_csv(TRAIN_Y_CSV, index=False, header=[TARGET_COL])\n",
    "# y_test.to_csv(TEST_Y_CSV, index=False, header=[TARGET_COL])\n",
    "\n",
    "# print(f\"Train - Rows: {len(X_train)}/Columns: {X_train.shape[1]}\")\n",
    "# print(\"First rows of train x:\")\n",
    "# print(X_train.head().to_string(index=False))\n",
    "# print(f\"Test - Rows: {len(X_test)}/Columns: {X_test.shape[1]}\")\n",
    "# print(\"First rows of train y:\")\n",
    "# print(y_train.head().to_string(index=False))\n",
    "# X_train.describe()\n",
    "\n",
    "# print(\"\\nTrain set class counts:\")\n",
    "# print(y_train.value_counts())\n",
    "# print(\"\\nTrain set class ratio:\")\n",
    "# print(y_train.value_counts(normalize=True))\n",
    "\n",
    "# print(\"\\nTest set class counts:\")\n",
    "# print(y_test.value_counts())\n",
    "# print(\"\\nTest set class ratio:\")\n",
    "# print(y_test.value_counts(normalize=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxipred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
