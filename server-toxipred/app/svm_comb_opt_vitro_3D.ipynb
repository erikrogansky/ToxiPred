{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb4f94d4",
   "metadata": {},
   "source": [
    "# SVM Tuning (Descriptors + Fingerprints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8630e1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from rdkit import Chem, RDLogger, DataStructs\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors, AllChem, MACCSkeys\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors as md\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    RepeatedStratifiedKFold,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    RandomizedSearchCV,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import shap\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6815b2a",
   "metadata": {},
   "source": [
    "## Molecule, Descriptor + Fingerprints and Outlier Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c03568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def molecule_from_smiles(smiles):\n",
    "    lg = RDLogger.logger()\n",
    "    # Temporarily silence RDKit logs\n",
    "    lg.setLevel(RDLogger.CRITICAL)\n",
    "    try:\n",
    "        # Extract molecule\n",
    "        molecule = Chem.MolFromSmiles(smiles, sanitize=True)\n",
    "        if molecule is None:\n",
    "            return None, \"failed\"\n",
    "\n",
    "        # Remove salts\n",
    "        clean_molecule = rdMolStandardize.LargestFragmentChooser()\n",
    "        molecule = clean_molecule.choose(molecule)\n",
    "\n",
    "        # Sanitize molecule again to reflect changes\n",
    "        Chem.SanitizeMol(molecule)\n",
    "        return molecule, \"succeed\"\n",
    "    except Exception as e:\n",
    "        return None, f\"error: {e}\"\n",
    "    finally:\n",
    "        # Re-enable logging afterward\n",
    "        lg.setLevel(RDLogger.INFO)\n",
    "\n",
    "\n",
    "def calculate_descriptors(molecule):\n",
    "    # Get all descriptors (1D/2D)\n",
    "    descriptor_names = []\n",
    "    for descriptor, _ in Descriptors._descList:\n",
    "        descriptor_names.append(descriptor)\n",
    "\n",
    "    # Use descriptors to calculate values\n",
    "    calculator = md.MolecularDescriptorCalculator(descriptor_names)\n",
    "    descriptor_values = calculator.CalcDescriptors(molecule)\n",
    "\n",
    "    # Create dictionary\n",
    "    descriptors = dict(zip(descriptor_names, descriptor_values))\n",
    "    return descriptors\n",
    "\n",
    "\n",
    "def compute_iqr_limits(df, factor=1.5):\n",
    "    # Calculate IQR limits\n",
    "    limits = {}\n",
    "    for col in df.columns:\n",
    "        q1 = df[col].quantile(0.25)\n",
    "        q3 = df[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        # If IQR is 0 - column is too flat - skip\n",
    "        if iqr == 0 or np.isnan(iqr):\n",
    "            continue\n",
    "\n",
    "        lower = q1 - factor * iqr\n",
    "        upper = q3 + factor * iqr\n",
    "        limits[col] = (lower, upper)\n",
    "    return limits\n",
    "\n",
    "\n",
    "def apply_iqr_limits(df, limits):\n",
    "    # Apply the limits\n",
    "    df_clipped = df.copy()\n",
    "    for col, (lower, upper) in limits.items():\n",
    "        df_clipped[col] = df_clipped[col].clip(lower, upper)\n",
    "    return df_clipped\n",
    "\n",
    "\n",
    "def bitvect_to_dict(fp, prefix):\n",
    "    # Convert bit vector to dictionary (create features)\n",
    "    n_bits = fp.GetNumBits()\n",
    "    arr = np.zeros((n_bits,), dtype=int)\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    features = {}\n",
    "    for i, v in enumerate(arr):\n",
    "        features[f\"{prefix}_{i}\"] = int(v)\n",
    "    return features\n",
    "\n",
    "\n",
    "def calculate_fingerprints(mol):\n",
    "    RDLogger.DisableLog(\"rdApp.*\")\n",
    "    # Calculate Morgan, RDKit, MACCS, AtomPair and Topological Torsion fingerprint\n",
    "    feats = {}\n",
    "    if mol is None:\n",
    "        return feats\n",
    "\n",
    "    # Morgan (ECFP) fingerprint\n",
    "    morgan_bits = 2048\n",
    "    morgan_radius = 2\n",
    "    fp_morgan = rdMolDescriptors.GetMorganFingerprintAsBitVect(\n",
    "        mol, radius=morgan_radius, nBits=morgan_bits\n",
    "    )\n",
    "    feats.update(bitvect_to_dict(fp_morgan, f\"Morgan{morgan_radius}_{morgan_bits}\"))\n",
    "\n",
    "    # RDKit topological fingerprint\n",
    "    rdk_bits = 2048\n",
    "    fp_rdk = Chem.RDKFingerprint(mol, fpSize=rdk_bits)\n",
    "    feats.update(bitvect_to_dict(fp_rdk, f\"RDK_{rdk_bits}\"))\n",
    "\n",
    "    # MACCS keys (167 bits)\n",
    "    fp_maccs = MACCSkeys.GenMACCSKeys(mol)\n",
    "    feats.update(bitvect_to_dict(fp_maccs, \"MACCS\"))\n",
    "\n",
    "    # AtomPair fingerprint\n",
    "    ap_bits = 2048\n",
    "    fp_ap = rdMolDescriptors.GetHashedAtomPairFingerprintAsBitVect(mol, nBits=ap_bits)\n",
    "    feats.update(bitvect_to_dict(fp_ap, f\"AtomPair_{ap_bits}\"))\n",
    "\n",
    "    # Topological torsion fingerprint\n",
    "    tt_bits = 2048\n",
    "    fp_tt = rdMolDescriptors.GetHashedTopologicalTorsionFingerprintAsBitVect(\n",
    "        mol, nBits=tt_bits\n",
    "    )\n",
    "    feats.update(bitvect_to_dict(fp_tt, f\"Torsion_{tt_bits}\"))\n",
    "\n",
    "    RDLogger.EnableLog(\"rdApp.*\")\n",
    "\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3bbfdb",
   "metadata": {},
   "source": [
    "## Dataset Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b75c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "ORIG_DATASET = \"in_vitro_3d_dataset.xlsx\"\n",
    "SKIP_ROWS = 1\n",
    "SMILES_COL = \"SMILES code\"\n",
    "TARGET_COL = \"Phototoxicity\"\n",
    "FULL_OUTPUT_DATASET = \"in_vitro_3d_dataset_processed.xlsx\"\n",
    "# Outputs\n",
    "TRAIN_X_CSV = \"in_vitro_3d_x_train.csv\"\n",
    "TEST_X_CSV = \"in_vitro_3d_x_test.csv\"\n",
    "TRAIN_Y_CSV = \"in_vitro_3d_y_train.csv\"\n",
    "TEST_Y_CSV = \"in_vitro_3d_y_test.csv\"\n",
    "\n",
    "# Near constant threshold - tolerance\n",
    "SIMILARITY_THRESHOLD = 0.7\n",
    "# Correlation threshold\n",
    "CORRELATION_THRESHOLD = 0.65\n",
    "\n",
    "# Load dataset and skip first row (Header)\n",
    "dataset = pd.read_excel(ORIG_DATASET, engine=\"openpyxl\", skiprows=SKIP_ROWS)\n",
    "\n",
    "descriptor_rows = []\n",
    "state_molecules = []\n",
    "molecules = []\n",
    "\n",
    "for smiles in dataset[SMILES_COL].astype(str):\n",
    "    molecule, state = molecule_from_smiles(smiles)\n",
    "    state_molecules.append(state)\n",
    "    molecules.append(molecule)\n",
    "\n",
    "    if molecule is None:\n",
    "        descriptor_rows.append({})\n",
    "        continue\n",
    "\n",
    "    # 1D/2D RDKit descriptors\n",
    "    desc_feats = calculate_descriptors(molecule)\n",
    "\n",
    "    # Calculate Morgan, RDKit, MACCS, AtomPair and Topological Torsion fingerprint\n",
    "    fp_feats = calculate_fingerprints(molecule)\n",
    "\n",
    "    # Merge both dicts into one feature row\n",
    "    all_feats = {**desc_feats, **fp_feats}\n",
    "    descriptor_rows.append(all_feats)\n",
    "\n",
    "# Convert list of dictionaries into dataframe\n",
    "descriptor_data_all = pd.DataFrame(descriptor_rows)\n",
    "\n",
    "# Keep everything + status\n",
    "output = pd.concat(\n",
    "    [dataset.reset_index(drop=True), descriptor_data_all.reset_index(drop=True)], axis=1\n",
    ")\n",
    "output[\"MoleculeStatus\"] = state_molecules\n",
    "\n",
    "# Output whole dataset with descriptors and state\n",
    "with pd.ExcelWriter(FULL_OUTPUT_DATASET, engine=\"openpyxl\") as writer:\n",
    "    output.to_excel(writer, index=False, sheet_name=\"Descriptors\")\n",
    "\n",
    "print(f\"Full - Rows: {len(output)}/Columns: {output.shape[1]}\")\n",
    "print(output.head().to_string(index=False))\n",
    "\n",
    "# Drop failed molecules - boolean array\n",
    "molecules_right = []\n",
    "for molecule in molecules:\n",
    "    if molecule is not None:\n",
    "        molecules_right.append(True)\n",
    "    else:\n",
    "        molecules_right.append(False)\n",
    "if not any(molecules_right):\n",
    "    raise ValueError(\"No valid molecules after SMILES parsing.\")\n",
    "\n",
    "dataset_ok = dataset.loc[molecules_right].reset_index(drop=True)\n",
    "descriptor_ok = descriptor_data_all.loc[molecules_right].reset_index(drop=True)\n",
    "\n",
    "# Target\n",
    "y_full = dataset_ok[TARGET_COL].astype(int)\n",
    "\n",
    "# Take only numeric descriptor columns\n",
    "X_full = descriptor_ok.select_dtypes(include=[np.number]).copy()\n",
    "for column in X_full.columns:\n",
    "    X_full[column] = X_full[column].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Drop columns that are entirely NaN\n",
    "all_nan_cols = X_full.columns[X_full.isna().all()].tolist()\n",
    "if all_nan_cols:\n",
    "    print(f\"Dropping {len(all_nan_cols)} NaN columns.\")\n",
    "    X_full = X_full.drop(columns=all_nan_cols)\n",
    "\n",
    "# Split dataset - train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_full, y_full, test_size=0.2, random_state=42, stratify=y_full\n",
    ")\n",
    "\n",
    "# Calculate medians for each column in train only\n",
    "train_medians = X_train.median(numeric_only=True)\n",
    "\n",
    "# Fill missing values in both train and test using those medians\n",
    "X_train = X_train.fillna(train_medians)\n",
    "X_test = X_test.fillna(train_medians)\n",
    "\n",
    "# Compute constants on train only\n",
    "constant_cols = []\n",
    "for col in X_train.columns:\n",
    "    top_freq = X_train[col].value_counts(normalize=True, dropna=False).max()\n",
    "    if top_freq >= SIMILARITY_THRESHOLD:\n",
    "        constant_cols.append(col)\n",
    "\n",
    "# Drop from train and apply same drop to test\n",
    "if constant_cols:\n",
    "    X_train = X_train.drop(columns=constant_cols)\n",
    "    X_test = X_test.drop(columns=constant_cols)\n",
    "    print(f\"Dropped {len(constant_cols)} constant/almost-constant columns.\")\n",
    "\n",
    "# Compute absolute correlation matrix on training data\n",
    "corr_matrix = X_train.corr().abs()\n",
    "# Keep only upper triangle of the matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "# Find columns to drop - correlation\n",
    "high_corr_cols = []\n",
    "for col in upper.columns:\n",
    "    if any(upper[col] > CORRELATION_THRESHOLD):\n",
    "        high_corr_cols.append(col)\n",
    "\n",
    "# Drop from both train and test\n",
    "if high_corr_cols:\n",
    "    X_train = X_train.drop(columns=high_corr_cols)\n",
    "    X_test = X_test.drop(columns=high_corr_cols)\n",
    "    print(f\"Dropped {len(high_corr_cols)} highly correlated columns.\")\n",
    "\n",
    "# Compute IQR limits on training data\n",
    "iqr_limits = compute_iqr_limits(X_train, factor=1.5)\n",
    "\n",
    "# Apply limits to both train and test sets\n",
    "X_train = apply_iqr_limits(X_train, iqr_limits)\n",
    "X_test = apply_iqr_limits(X_test, iqr_limits)\n",
    "\n",
    "# Scaling not necessary for all models\n",
    "# Splitting the dataset to Fingerprint and Descriptor sets\n",
    "FP_PREFIXES = (\n",
    "    \"Morgan\",\n",
    "    \"RDK_\",\n",
    "    \"MACCS\",\n",
    "    \"AtomPair_\",\n",
    "    \"Torsion_\",\n",
    ")  # Identify fingerprint columns by prefix\n",
    "fp_cols = [c for c in X_train.columns if c.startswith(FP_PREFIXES)]\n",
    "desc_cols = [c for c in X_train.columns if c not in fp_cols]\n",
    "\n",
    "print(f\"Descriptor columns: {len(desc_cols)}, fingerprint columns: {len(fp_cols)}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "if desc_cols:\n",
    "    X_train_desc_scaled = scaler.fit_transform(X_train[desc_cols])\n",
    "    X_test_desc_scaled = scaler.transform(X_test[desc_cols])\n",
    "\n",
    "    # Start from copies so we keep original indexing and all columns\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "    # Overwrite only descriptor columns with scaled values\n",
    "    X_train_scaled[desc_cols] = X_train_desc_scaled\n",
    "    X_test_scaled[desc_cols] = X_test_desc_scaled\n",
    "else:\n",
    "    X_train_scaled = X_train.copy()\n",
    "    X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train = X_train_scaled\n",
    "X_test = X_test_scaled\n",
    "\n",
    "# Save processed datasets\n",
    "X_train.to_csv(TRAIN_X_CSV, index=False)\n",
    "X_test.to_csv(TEST_X_CSV, index=False)\n",
    "y_train.to_csv(TRAIN_Y_CSV, index=False, header=[TARGET_COL])\n",
    "y_test.to_csv(TEST_Y_CSV, index=False, header=[TARGET_COL])\n",
    "\n",
    "print(f\"Train - Rows: {len(X_train)}/Columns: {X_train.shape[1]}\")\n",
    "print(\"First rows of train x:\")\n",
    "print(X_train.head().to_string(index=False))\n",
    "print(f\"Test - Rows: {len(X_test)}/Columns: {X_test.shape[1]}\")\n",
    "print(\"First rows of train y:\")\n",
    "print(y_train.head().to_string(index=False))\n",
    "X_train.describe()\n",
    "\n",
    "print(\"\\nTrain set class counts:\")\n",
    "print(y_train.value_counts())\n",
    "print(\"\\nTrain set class ratio:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nTest set class counts:\")\n",
    "print(y_test.value_counts())\n",
    "print(\"\\nTest set class ratio:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e932ef57",
   "metadata": {},
   "source": [
    "## Base Model Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM pipeline: scale features + RBF-kernel SVM with calibrated probabilities\n",
    "base_model = SVC(\n",
    "    kernel=\"rbf\",\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Train\n",
    "base_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = base_model.predict(X_test)\n",
    "y_prob = base_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"\\nModel performance (SVM):\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "print(f\"ROC AUC:   {auc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_test, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb159ee0",
   "metadata": {},
   "source": [
    "## Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b426f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP features\n",
    "# Prediction function for SHAP\n",
    "f = lambda X: base_model.predict_proba(X)[:, 1]\n",
    "\n",
    "# explainer = shap.Explainer(f, X_train)\n",
    "shap_result = explainer(X_train, max_evals=2 * X_train.shape[1] + 50)\n",
    "\n",
    "# Each row has values for features\n",
    "shap_values = shap_result.values\n",
    "\n",
    "# Mean absolute SHAP value per feature (importance)\n",
    "shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "shap_features = pd.Series(shap_importance, index=X_train.columns).sort_values(\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "# K-Best - Anova features\n",
    "kbest = SelectKBest(score_func=f_classif, k=\"all\")\n",
    "kbest.fit(X_train, y_train)\n",
    "kbest_scores = pd.Series(kbest.scores_, index=X_train.columns).fillna(0.0)\n",
    "kbest_features = kbest_scores.sort_values(ascending=False)\n",
    "\n",
    "# Lasso features\n",
    "lasso = LogisticRegression(penalty=\"l1\", C=1.0, solver=\"liblinear\", max_iter=5000)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "lasso_importance = pd.Series(np.abs(lasso.coef_).ravel(), index=X_train.columns)\n",
    "lasso_features = lasso_importance.sort_values(ascending=False)\n",
    "\n",
    "# Plot\n",
    "shap.summary_plot(shap_values, X_train)\n",
    "\n",
    "# Print best features for each method\n",
    "print(\"\\nTop 10 SHAP features:\")\n",
    "print(shap_features.head(10).to_string())\n",
    "print(\"\\nTop 10 K-Best features:\")\n",
    "print(kbest_features.head(10).to_string())\n",
    "print(\"\\nTop 10 Lasso features:\")\n",
    "print(lasso_features.head(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafe4108",
   "metadata": {},
   "source": [
    "## SHAP Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15651a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_features.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a0a7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate from top 5 features up to all\n",
    "for n in range(5, len(shap_features) + 1):\n",
    "    top_feats = shap_features.head(n).index\n",
    "\n",
    "    model = SVC(\n",
    "        kernel=\"rbf\",\n",
    "        probability=True,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    # Cross validation\n",
    "    cv_res = cross_validate(\n",
    "        model,\n",
    "        X_train[top_feats],\n",
    "        y_train,\n",
    "        cv=kf,\n",
    "        scoring={\"accuracy\": \"accuracy\", \"f1\": \"f1\", \"roc_auc\": \"roc_auc\"},\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "\n",
    "    mean_acc = cv_res[\"test_accuracy\"].mean()\n",
    "    mean_f1 = cv_res[\"test_f1\"].mean()\n",
    "    mean_auc = cv_res[\"test_roc_auc\"].mean()\n",
    "\n",
    "    results.append((n, mean_acc, mean_f1, mean_auc))\n",
    "\n",
    "# Results DataFrame\n",
    "res_df = pd.DataFrame(results, columns=[\"Top_N\", \"CV_Accuracy\", \"CV_F1\", \"CV_ROC_AUC\"])\n",
    "\n",
    "# Pick best N by CV F1\n",
    "best = res_df.iloc[res_df[\"CV_F1\"].idxmax()]\n",
    "best_n = int(best.Top_N)\n",
    "best_n_shap = int(best.Top_N)\n",
    "\n",
    "print(\"\\nCV results (training only, mean over folds):\")\n",
    "print(res_df.head())\n",
    "print(f\"\\nBest number of features by CV F1: {best_n}\")\n",
    "print(best)\n",
    "\n",
    "# Plot CV performance\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(res_df[\"Top_N\"], res_df[\"CV_Accuracy\"], label=\"CV Accuracy\")\n",
    "plt.plot(res_df[\"Top_N\"], res_df[\"CV_F1\"], label=\"CV F1\")\n",
    "plt.plot(res_df[\"Top_N\"], res_df[\"CV_ROC_AUC\"], label=\"CV ROC AUC\")\n",
    "plt.xlabel(\"Number of top SHAP features\")\n",
    "plt.ylabel(\"Mean CV score\")\n",
    "plt.title(\"CV performance vs number of top SHAP features\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f435a546",
   "metadata": {},
   "source": [
    "## KBEST Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f504d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest_features.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af72e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate from top 5 features up to all\n",
    "for n in range(5, len(kbest_features) + 1):\n",
    "    top_feats = kbest_features.head(n).index\n",
    "\n",
    "    # model = xgb.XGBClassifier(\n",
    "    #     objective=\"binary:logistic\", eval_metric=[\"logloss\", \"auc\"], random_state=42\n",
    "    # )\n",
    "\n",
    "    model = SVC(\n",
    "        kernel=\"rbf\",\n",
    "        probability=True,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    # Cross validation\n",
    "    cv_res = cross_validate(\n",
    "        model,\n",
    "        X_train[top_feats],\n",
    "        y_train,\n",
    "        cv=kf,\n",
    "        scoring={\"accuracy\": \"accuracy\", \"f1\": \"f1\", \"roc_auc\": \"roc_auc\"},\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "\n",
    "    mean_acc = cv_res[\"test_accuracy\"].mean()\n",
    "    mean_f1 = cv_res[\"test_f1\"].mean()\n",
    "    mean_auc = cv_res[\"test_roc_auc\"].mean()\n",
    "\n",
    "    results.append((n, mean_acc, mean_f1, mean_auc))\n",
    "\n",
    "# Results DataFrame\n",
    "res_df = pd.DataFrame(results, columns=[\"Top_N\", \"CV_Accuracy\", \"CV_F1\", \"CV_ROC_AUC\"])\n",
    "\n",
    "# Pick best N by CV F1\n",
    "best = res_df.iloc[res_df[\"CV_F1\"].idxmax()]\n",
    "best_n = int(best.Top_N)\n",
    "best_n_kbest = int(best.Top_N)\n",
    "\n",
    "print(\"\\nCV results (training only, mean over folds):\")\n",
    "print(res_df.head())\n",
    "print(f\"\\nBest number of features by CV F1: {best_n}\")\n",
    "print(best)\n",
    "\n",
    "# Plot CV performance\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(res_df[\"Top_N\"], res_df[\"CV_Accuracy\"], label=\"CV Accuracy\")\n",
    "plt.plot(res_df[\"Top_N\"], res_df[\"CV_F1\"], label=\"CV F1\")\n",
    "plt.plot(res_df[\"Top_N\"], res_df[\"CV_ROC_AUC\"], label=\"CV ROC AUC\")\n",
    "plt.xlabel(\"Number of top KBEST features\")\n",
    "plt.ylabel(\"Mean CV score\")\n",
    "plt.title(\"CV performance vs number of top KBEST features\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a71dae",
   "metadata": {},
   "source": [
    "## LASSO Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d564b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_features.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dfb820",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate from top 5 features up to all\n",
    "for n in range(5, len(lasso_features) + 1):\n",
    "    top_feats = lasso_features.head(n).index\n",
    "\n",
    "    model = SVC(\n",
    "        kernel=\"rbf\",\n",
    "        probability=True,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    # Cross validation\n",
    "    cv_res = cross_validate(\n",
    "        model,\n",
    "        X_train[top_feats],\n",
    "        y_train,\n",
    "        cv=kf,\n",
    "        scoring={\"accuracy\": \"accuracy\", \"f1\": \"f1\", \"roc_auc\": \"roc_auc\"},\n",
    "        n_jobs=-1,\n",
    "        return_train_score=False,\n",
    "    )\n",
    "\n",
    "    mean_acc = cv_res[\"test_accuracy\"].mean()\n",
    "    mean_f1 = cv_res[\"test_f1\"].mean()\n",
    "    mean_auc = cv_res[\"test_roc_auc\"].mean()\n",
    "\n",
    "    results.append((n, mean_acc, mean_f1, mean_auc))\n",
    "\n",
    "# Results DataFrame\n",
    "res_df = pd.DataFrame(results, columns=[\"Top_N\", \"CV_Accuracy\", \"CV_F1\", \"CV_ROC_AUC\"])\n",
    "\n",
    "# Pick best N by CV F1\n",
    "best = res_df.iloc[res_df[\"CV_F1\"].idxmax()]\n",
    "best_n = int(best.Top_N)\n",
    "best_n_lasso = int(best.Top_N)\n",
    "\n",
    "print(\"\\nCV results (training only, mean over folds):\")\n",
    "print(res_df.head())\n",
    "print(f\"\\nBest number of features by CV F1: {best_n}\")\n",
    "print(best)\n",
    "\n",
    "# Plot CV performance\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(res_df[\"Top_N\"], res_df[\"CV_Accuracy\"], label=\"CV Accuracy\")\n",
    "plt.plot(res_df[\"Top_N\"], res_df[\"CV_F1\"], label=\"CV F1\")\n",
    "plt.plot(res_df[\"Top_N\"], res_df[\"CV_ROC_AUC\"], label=\"CV ROC AUC\")\n",
    "plt.xlabel(\"Number of top LASSO features\")\n",
    "plt.ylabel(\"Mean CV score\")\n",
    "plt.title(\"CV performance vs number of top LASSO features\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7254572f",
   "metadata": {},
   "source": [
    "## Model SHAP Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ae0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feats = shap_features.head(best_n_shap).index.tolist()\n",
    "\n",
    "# Train final model\n",
    "final_model = SVC(\n",
    "    kernel=\"rbf\",\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "final_model.fit(X_train[top_feats], y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = final_model.predict(X_test[top_feats])\n",
    "y_prob = final_model.predict_proba(X_test[top_feats])[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"\\nFinal model performance (SHAP) on test:\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "print(f\"ROC AUC:   {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e9f494",
   "metadata": {},
   "source": [
    "## Model KBEST Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9987cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feats = kbest_features.head(best_n_kbest).index.tolist()\n",
    "\n",
    "# Train final model\n",
    "final_model = SVC(\n",
    "    kernel=\"rbf\",\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "final_model.fit(X_train[top_feats], y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = final_model.predict(X_test[top_feats])\n",
    "y_prob = final_model.predict_proba(X_test[top_feats])[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"\\nFinal model performance (KBEST) on test:\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "print(f\"ROC AUC:   {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7149d261",
   "metadata": {},
   "source": [
    "## Model LASSO Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839019d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feats = lasso_features.head(best_n_lasso).index.tolist()\n",
    "\n",
    "# Train final model\n",
    "final_model = SVC(\n",
    "    kernel=\"rbf\",\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "final_model.fit(X_train[top_feats], y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = final_model.predict(X_test[top_feats])\n",
    "y_prob = final_model.predict_proba(X_test[top_feats])[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"\\nFinal model performance (LASSO) on test:\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "print(f\"ROC AUC:   {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40781606",
   "metadata": {},
   "source": [
    "## Model SHAP Features Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0199f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feats = shap_features.head(best_n_shap).index.tolist()\n",
    "\n",
    "X_train_fs = X_train[top_feats]\n",
    "X_test_fs = X_test[top_feats]\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "\n",
    "# Optuna\n",
    "def objective(trial):\n",
    "    # ---- Optuna param space for SVM ----\n",
    "    params = {\n",
    "        \"kernel\": trial.suggest_categorical(\n",
    "            \"kernel\", [\"rbf\", \"linear\", \"poly\", \"sigmoid\"]\n",
    "        ),\n",
    "        \"C\": trial.suggest_float(\"C\", 1e-3, 1e3, log=True),\n",
    "        \"class_weight\": trial.suggest_categorical(\"class_weight\", [None, \"balanced\"]),\n",
    "        \"shrinking\": trial.suggest_categorical(\"shrinking\", [True, False]),\n",
    "        \"tol\": trial.suggest_float(\"tol\", 1e-5, 1e-2, log=True),\n",
    "        \"max_iter\": trial.suggest_categorical(\"max_iter\", [-1, 1000, 2000]),\n",
    "        \"probability\": True,  # needed if you evaluate with predicted probabilities (e.g., ROC AUC)\n",
    "        \"random_state\": 42,\n",
    "        \"cache_size\": 1000.0,\n",
    "    }\n",
    "\n",
    "    # gamma choice: allow \"scale\"/\"auto\" or a numeric value\n",
    "    gamma_mode = trial.suggest_categorical(\"gamma_mode\", [\"scale\", \"auto\", \"float\"])\n",
    "    if gamma_mode == \"float\":\n",
    "        params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-4, 10.0, log=True)\n",
    "    else:\n",
    "        params[\"gamma\"] = gamma_mode\n",
    "\n",
    "    # conditionals for poly/sigmoid\n",
    "    if params[\"kernel\"] == \"poly\":\n",
    "        params[\"degree\"] = trial.suggest_int(\"degree\", 2, 5)\n",
    "        params[\"coef0\"] = trial.suggest_float(\"coef0\", 0.0, 1.0)\n",
    "    elif params[\"kernel\"] == \"sigmoid\":\n",
    "        params[\"coef0\"] = trial.suggest_float(\"coef0\", 0.0, 1.0)\n",
    "    # for \"rbf\" and \"linear\" degree/coef0 are ignored, so we omit them\n",
    "\n",
    "    # ---- Model ----\n",
    "    model = SVC(**params)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # CV\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X_train_fs,\n",
    "        y_train,\n",
    "        cv=cv,\n",
    "        # scoring=\"f1\",\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "# Study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=200, show_progress_bar=True)\n",
    "\n",
    "print(\"\\nBest trial:\")\n",
    "print(\"  Value:\", study.best_value)\n",
    "print(\"  Params:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"    {k}: {v}\")\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "\n",
    "# Map gamma_mode -> gamma\n",
    "gamma_mode = best_params.pop(\"gamma_mode\", \"scale\")\n",
    "if gamma_mode != \"float\":\n",
    "    # 'scale' or 'auto'\n",
    "    best_params[\"gamma\"] = gamma_mode\n",
    "# else: when gamma_mode == 'float', Optuna already stored a numeric 'gamma' in best_params\n",
    "\n",
    "best_params.update(\n",
    "    {\n",
    "        \"probability\": True,  # needed for predict_proba below\n",
    "        \"random_state\": 42,\n",
    "        \"cache_size\": 1000.0,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Final model\n",
    "final_model = SVC(**best_params)\n",
    "final_model.fit(X_train_fs, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = final_model.predict(X_test_fs)\n",
    "y_prob = final_model.predict_proba(X_test_fs)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"\\nFinal Optuna model (SHAP):\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "print(f\"ROC AUC:   {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9101bc0",
   "metadata": {},
   "source": [
    "## Model KBEST Features Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feats = kbest_features.head(best_n_kbest).index.tolist()\n",
    "\n",
    "X_train_fs = X_train[top_feats]\n",
    "X_test_fs = X_test[top_feats]\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "\n",
    "# Optuna\n",
    "def objective(trial):\n",
    "    # Hyperparameter search space\n",
    "    # ---- Optuna param space for SVM ----\n",
    "    params = {\n",
    "        \"kernel\": trial.suggest_categorical(\n",
    "            \"kernel\", [\"rbf\", \"linear\", \"poly\", \"sigmoid\"]\n",
    "        ),\n",
    "        \"C\": trial.suggest_float(\"C\", 1e-3, 1e3, log=True),\n",
    "        \"class_weight\": trial.suggest_categorical(\"class_weight\", [None, \"balanced\"]),\n",
    "        \"shrinking\": trial.suggest_categorical(\"shrinking\", [True, False]),\n",
    "        \"tol\": trial.suggest_float(\"tol\", 1e-5, 1e-2, log=True),\n",
    "        \"max_iter\": trial.suggest_categorical(\"max_iter\", [-1, 1000, 2000]),\n",
    "        \"probability\": True,  # needed if you evaluate with predicted probabilities (e.g., ROC AUC)\n",
    "        \"random_state\": 42,\n",
    "        \"cache_size\": 1000.0,\n",
    "    }\n",
    "\n",
    "    # gamma choice: allow \"scale\"/\"auto\" or a numeric value\n",
    "    gamma_mode = trial.suggest_categorical(\"gamma_mode\", [\"scale\", \"auto\", \"float\"])\n",
    "    if gamma_mode == \"float\":\n",
    "        params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-4, 10.0, log=True)\n",
    "    else:\n",
    "        params[\"gamma\"] = gamma_mode\n",
    "\n",
    "    # conditionals for poly/sigmoid\n",
    "    if params[\"kernel\"] == \"poly\":\n",
    "        params[\"degree\"] = trial.suggest_int(\"degree\", 2, 5)\n",
    "        params[\"coef0\"] = trial.suggest_float(\"coef0\", 0.0, 1.0)\n",
    "    elif params[\"kernel\"] == \"sigmoid\":\n",
    "        params[\"coef0\"] = trial.suggest_float(\"coef0\", 0.0, 1.0)\n",
    "    # for \"rbf\" and \"linear\" degree/coef0 are ignored, so we omit them\n",
    "\n",
    "    # ---- Model ----\n",
    "    model = SVC(**params)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # CV\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X_train_fs,\n",
    "        y_train,\n",
    "        cv=cv,\n",
    "        scoring=\"f1\",\n",
    "        # scoring=\"roc_auc\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "# Study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=200, show_progress_bar=True)\n",
    "\n",
    "print(\"\\nBest trial:\")\n",
    "print(\"  Value:\", study.best_value)\n",
    "print(\"  Params:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"    {k}: {v}\")\n",
    "\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "\n",
    "# Map gamma_mode -> gamma\n",
    "gamma_mode = best_params.pop(\"gamma_mode\", \"scale\")\n",
    "if gamma_mode != \"float\":\n",
    "    # 'scale' or 'auto'\n",
    "    best_params[\"gamma\"] = gamma_mode\n",
    "# else: when gamma_mode == 'float', Optuna already stored a numeric 'gamma' in best_params\n",
    "\n",
    "best_params.update(\n",
    "    {\n",
    "        \"probability\": True,  # needed for predict_proba below\n",
    "        \"random_state\": 42,\n",
    "        \"cache_size\": 1000.0,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Final model\n",
    "final_model = SVC(**best_params)\n",
    "final_model.fit(X_train_fs, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = final_model.predict(X_test_fs)\n",
    "y_prob = final_model.predict_proba(X_test_fs)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"\\nFinal Optuna model (KBEST):\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "print(f\"ROC AUC:   {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed7caaa",
   "metadata": {},
   "source": [
    "## Model LASSO Features Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790bce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feats = lasso_features.head(best_n_lasso).index.tolist()\n",
    "\n",
    "X_train_fs = X_train[top_feats]\n",
    "X_test_fs = X_test[top_feats]\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "\n",
    "# Optuna\n",
    "def objective(trial):\n",
    "    # ---- Optuna param space for SVM ----\n",
    "    params = {\n",
    "        \"kernel\": trial.suggest_categorical(\n",
    "            \"kernel\", [\"rbf\", \"linear\", \"poly\", \"sigmoid\"]\n",
    "        ),\n",
    "        \"C\": trial.suggest_float(\"C\", 1e-3, 1e3, log=True),\n",
    "        \"class_weight\": trial.suggest_categorical(\"class_weight\", [None, \"balanced\"]),\n",
    "        \"shrinking\": trial.suggest_categorical(\"shrinking\", [True, False]),\n",
    "        \"tol\": trial.suggest_float(\"tol\", 1e-5, 1e-2, log=True),\n",
    "        \"max_iter\": trial.suggest_categorical(\"max_iter\", [-1, 1000, 2000]),\n",
    "        \"probability\": True,  # needed if you evaluate with predicted probabilities (e.g., ROC AUC)\n",
    "        \"random_state\": 42,\n",
    "        \"cache_size\": 1000.0,\n",
    "    }\n",
    "\n",
    "    # gamma choice: allow \"scale\"/\"auto\" or a numeric value\n",
    "    gamma_mode = trial.suggest_categorical(\"gamma_mode\", [\"scale\", \"auto\", \"float\"])\n",
    "    if gamma_mode == \"float\":\n",
    "        params[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-4, 10.0, log=True)\n",
    "    else:\n",
    "        params[\"gamma\"] = gamma_mode\n",
    "\n",
    "    # conditionals for poly/sigmoid\n",
    "    if params[\"kernel\"] == \"poly\":\n",
    "        params[\"degree\"] = trial.suggest_int(\"degree\", 2, 5)\n",
    "        params[\"coef0\"] = trial.suggest_float(\"coef0\", 0.0, 1.0)\n",
    "    elif params[\"kernel\"] == \"sigmoid\":\n",
    "        params[\"coef0\"] = trial.suggest_float(\"coef0\", 0.0, 1.0)\n",
    "    # for \"rbf\" and \"linear\" degree/coef0 are ignored, so we omit them\n",
    "\n",
    "    # ---- Model ----\n",
    "    model = SVC(**params)\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # CV\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X_train_fs,\n",
    "        y_train,\n",
    "        cv=cv,\n",
    "        # scoring=\"f1\",\n",
    "        scoring=\"roc_auc\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "# Study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=200, show_progress_bar=True)\n",
    "\n",
    "print(\"\\nBest trial:\")\n",
    "print(\"  Value:\", study.best_value)\n",
    "print(\"  Params:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"    {k}: {v}\")\n",
    "\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "\n",
    "# Map gamma_mode -> gamma\n",
    "gamma_mode = best_params.pop(\"gamma_mode\", \"scale\")\n",
    "if gamma_mode != \"float\":\n",
    "    # 'scale' or 'auto'\n",
    "    best_params[\"gamma\"] = gamma_mode\n",
    "# else: when gamma_mode == 'float', Optuna already stored a numeric 'gamma' in best_params\n",
    "\n",
    "best_params.update(\n",
    "    {\n",
    "        \"probability\": True,  # needed for predict_proba below\n",
    "        \"random_state\": 42,\n",
    "        \"cache_size\": 1000.0,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Final model\n",
    "final_model = SVC(**best_params)\n",
    "final_model.fit(X_train_fs, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = final_model.predict(X_test_fs)\n",
    "y_prob = final_model.predict_proba(X_test_fs)[:, 1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred)\n",
    "rec = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"\\nFinal Optuna model (LASSO):\")\n",
    "print(f\"Accuracy:  {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall:    {rec:.4f}\")\n",
    "print(f\"F1 score:  {f1:.4f}\")\n",
    "print(f\"ROC AUC:   {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a3152d",
   "metadata": {},
   "source": [
    "## Model SHAP Features Tuning (Randomized Search CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a9e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = shap_features\n",
    "\n",
    "# Search spaces per kernel (lists => sampled uniformly)\n",
    "search_spaces = [\n",
    "    # linear\n",
    "    {\n",
    "        \"kernel\": [\"linear\"],\n",
    "        \"C\": list(np.logspace(-3, 3, 200)),\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"shrinking\": [True, False],\n",
    "        \"tol\": list(np.logspace(-5, -2, 50)),\n",
    "        \"max_iter\": [-1, 1000, 2000],\n",
    "    },\n",
    "    # rbf\n",
    "    {\n",
    "        \"kernel\": [\"rbf\"],\n",
    "        \"C\": list(np.logspace(-3, 3, 200)),\n",
    "        \"gamma\": ([\"scale\", \"auto\"] + list(np.logspace(-4, 1, 200))),\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"shrinking\": [True, False],\n",
    "        \"tol\": list(np.logspace(-5, -2, 50)),\n",
    "        \"max_iter\": [-1, 1000, 2000],\n",
    "    },\n",
    "    # poly\n",
    "    {\n",
    "        \"kernel\": [\"poly\"],\n",
    "        \"C\": list(np.logspace(-3, 3, 200)),\n",
    "        \"gamma\": ([\"scale\", \"auto\"] + list(np.logspace(-4, 1, 200))),\n",
    "        \"degree\": [2, 3, 4, 5],\n",
    "        \"coef0\": list(np.linspace(0.0, 1.0, 21)),\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"shrinking\": [True, False],\n",
    "        \"tol\": list(np.logspace(-5, -2, 50)),\n",
    "        \"max_iter\": [-1, 1000, 2000],\n",
    "    },\n",
    "    # sigmoid\n",
    "    {\n",
    "        \"kernel\": [\"sigmoid\"],\n",
    "        \"C\": list(np.logspace(-3, 3, 200)),\n",
    "        \"gamma\": ([\"scale\", \"auto\"] + list(np.logspace(-4, 1, 200))),\n",
    "        \"coef0\": list(np.linspace(0.0, 1.0, 21)),\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"shrinking\": [True, False],\n",
    "        \"tol\": list(np.logspace(-5, -2, 50)),\n",
    "        \"max_iter\": [-1, 1000, 2000],\n",
    "    },\n",
    "]\n",
    "\n",
    "results = []\n",
    "for k in range(5, 55):\n",
    "    print(f\"\\n=== Testing top {k} features ===\")\n",
    "    top_feats = ranking.head(k).index.tolist()\n",
    "    X_train_sel = X_train[top_feats]\n",
    "    X_test_sel = X_test[top_feats]\n",
    "\n",
    "    base = SVC(probability=True, random_state=42, cache_size=1000.0)\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=base,\n",
    "        param_distributions=search_spaces,  # list of dicts => supports conditionals\n",
    "        n_iter=80,\n",
    "        scoring=\"roc_auc\",  # align search with AUC\n",
    "        cv=3,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=0,\n",
    "        error_score=\"raise\",\n",
    "    )\n",
    "\n",
    "    search.fit(X_train_sel, y_train)\n",
    "\n",
    "    best_model = search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_sel)\n",
    "    y_prob = best_model.predict_proba(X_test_sel)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    results.append((k, acc, auc))\n",
    "\n",
    "    print(f\"Best parameters: {search.best_params_}\")\n",
    "    print(f\"Accuracy: {acc:.3f} | ROC-AUC: {auc:.3f}\")\n",
    "\n",
    "# Analyze\n",
    "results = np.array(results, dtype=float)\n",
    "feature_counts = results[:, 0]\n",
    "accuracies = results[:, 1]\n",
    "auc_scores = results[:, 2]\n",
    "\n",
    "best_index = np.argmax(accuracies)\n",
    "best_k = int(feature_counts[best_index])\n",
    "best_acc = accuracies[best_index]\n",
    "best_auc = auc_scores[best_index]\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(feature_counts, accuracies, \"o-\", label=\"Accuracy\")\n",
    "plt.plot(feature_counts, auc_scores, \"s--\", label=\"ROC-AUC\")\n",
    "plt.scatter(\n",
    "    best_k, best_acc, s=100, zorder=5, label=f\"Accuracy={best_acc:.3f}/k={best_k}\"\n",
    ")\n",
    "plt.title(\"SVM performance\")\n",
    "plt.xlabel(\"Number of selected features\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAccuracy = {best_acc:.3f} | ROC-AUC = {best_auc:.3f} | k = {best_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691aa2d0",
   "metadata": {},
   "source": [
    "## Model KBEST Features Tuning (Randomized Search CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f00a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = kbest_features\n",
    "\n",
    "# Search spaces per kernel (lists => sampled uniformly)\n",
    "search_spaces = [\n",
    "    # linear\n",
    "    {\n",
    "        \"kernel\": [\"linear\"],\n",
    "        \"C\": list(np.logspace(-3, 3, 200)),\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"shrinking\": [True, False],\n",
    "        \"tol\": list(np.logspace(-5, -2, 50)),\n",
    "        \"max_iter\": [-1, 1000, 2000],\n",
    "    },\n",
    "    # rbf\n",
    "    {\n",
    "        \"kernel\": [\"rbf\"],\n",
    "        \"C\": list(np.logspace(-3, 3, 200)),\n",
    "        \"gamma\": ([\"scale\", \"auto\"] + list(np.logspace(-4, 1, 200))),\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"shrinking\": [True, False],\n",
    "        \"tol\": list(np.logspace(-5, -2, 50)),\n",
    "        \"max_iter\": [-1, 1000, 2000],\n",
    "    },\n",
    "    # poly\n",
    "    {\n",
    "        \"kernel\": [\"poly\"],\n",
    "        \"C\": list(np.logspace(-3, 3, 200)),\n",
    "        \"gamma\": ([\"scale\", \"auto\"] + list(np.logspace(-4, 1, 200))),\n",
    "        \"degree\": [2, 3, 4, 5],\n",
    "        \"coef0\": list(np.linspace(0.0, 1.0, 21)),\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"shrinking\": [True, False],\n",
    "        \"tol\": list(np.logspace(-5, -2, 50)),\n",
    "        \"max_iter\": [-1, 1000, 2000],\n",
    "    },\n",
    "    # sigmoid\n",
    "    {\n",
    "        \"kernel\": [\"sigmoid\"],\n",
    "        \"C\": list(np.logspace(-3, 3, 200)),\n",
    "        \"gamma\": ([\"scale\", \"auto\"] + list(np.logspace(-4, 1, 200))),\n",
    "        \"coef0\": list(np.linspace(0.0, 1.0, 21)),\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"shrinking\": [True, False],\n",
    "        \"tol\": list(np.logspace(-5, -2, 50)),\n",
    "        \"max_iter\": [-1, 1000, 2000],\n",
    "    },\n",
    "]\n",
    "\n",
    "results = []\n",
    "for k in range(5, 55):\n",
    "    print(f\"\\n=== Testing top {k} features ===\")\n",
    "    top_feats = ranking.head(k).index.tolist()\n",
    "    X_train_sel = X_train[top_feats]\n",
    "    X_test_sel = X_test[top_feats]\n",
    "\n",
    "    base = SVC(probability=True, random_state=42, cache_size=1000.0)\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=base,\n",
    "        param_distributions=search_spaces,  # list of dicts => supports conditionals\n",
    "        n_iter=80,\n",
    "        scoring=\"roc_auc\",  # align search with AUC\n",
    "        cv=3,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=0,\n",
    "        error_score=\"raise\",\n",
    "    )\n",
    "\n",
    "    search.fit(X_train_sel, y_train)\n",
    "\n",
    "    best_model = search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_sel)\n",
    "    y_prob = best_model.predict_proba(X_test_sel)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    results.append((k, acc, auc))\n",
    "\n",
    "    print(f\"Best parameters: {search.best_params_}\")\n",
    "    print(f\"Accuracy: {acc:.3f} | ROC-AUC: {auc:.3f}\")\n",
    "\n",
    "# Analyze\n",
    "results = np.array(results, dtype=float)\n",
    "feature_counts = results[:, 0]\n",
    "accuracies = results[:, 1]\n",
    "auc_scores = results[:, 2]\n",
    "\n",
    "best_index = np.argmax(accuracies)\n",
    "best_k = int(feature_counts[best_index])\n",
    "best_acc = accuracies[best_index]\n",
    "best_auc = auc_scores[best_index]\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(feature_counts, accuracies, \"o-\", label=\"Accuracy\")\n",
    "plt.plot(feature_counts, auc_scores, \"s--\", label=\"ROC-AUC\")\n",
    "plt.scatter(\n",
    "    best_k, best_acc, s=100, zorder=5, label=f\"Accuracy={best_acc:.3f}/k={best_k}\"\n",
    ")\n",
    "plt.title(\"SVM performance\")\n",
    "plt.xlabel(\"Number of selected features\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAccuracy = {best_acc:.3f} | ROC-AUC = {best_auc:.3f} | k = {best_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e7d440",
   "metadata": {},
   "source": [
    "## Model LASSO Features Tuning (Randomized Search CV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dfd957",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = lasso_features\n",
    "\n",
    "# Search spaces per kernel (lists => sampled uniformly)\n",
    "search_spaces = [\n",
    "    # linear\n",
    "    {\n",
    "        \"kernel\": [\"linear\"],\n",
    "        \"C\": list(np.logspace(-3, 3, 200)),\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"shrinking\": [True, False],\n",
    "        \"tol\": list(np.logspace(-5, -2, 50)),\n",
    "        \"max_iter\": [-1, 1000, 2000],\n",
    "    },\n",
    "    # rbf\n",
    "    {\n",
    "        \"kernel\": [\"rbf\"],\n",
    "        \"C\": list(np.logspace(-3, 3, 200)),\n",
    "        \"gamma\": ([\"scale\", \"auto\"] + list(np.logspace(-4, 1, 200))),\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"shrinking\": [True, False],\n",
    "        \"tol\": list(np.logspace(-5, -2, 50)),\n",
    "        \"max_iter\": [-1, 1000, 2000],\n",
    "    },\n",
    "    # poly\n",
    "    {\n",
    "        \"kernel\": [\"poly\"],\n",
    "        \"C\": list(np.logspace(-3, 3, 200)),\n",
    "        \"gamma\": ([\"scale\", \"auto\"] + list(np.logspace(-4, 1, 200))),\n",
    "        \"degree\": [2, 3, 4, 5],\n",
    "        \"coef0\": list(np.linspace(0.0, 1.0, 21)),\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"shrinking\": [True, False],\n",
    "        \"tol\": list(np.logspace(-5, -2, 50)),\n",
    "        \"max_iter\": [-1, 1000, 2000],\n",
    "    },\n",
    "    # sigmoid\n",
    "    {\n",
    "        \"kernel\": [\"sigmoid\"],\n",
    "        \"C\": list(np.logspace(-3, 3, 200)),\n",
    "        \"gamma\": ([\"scale\", \"auto\"] + list(np.logspace(-4, 1, 200))),\n",
    "        \"coef0\": list(np.linspace(0.0, 1.0, 21)),\n",
    "        \"class_weight\": [None, \"balanced\"],\n",
    "        \"shrinking\": [True, False],\n",
    "        \"tol\": list(np.logspace(-5, -2, 50)),\n",
    "        \"max_iter\": [-1, 1000, 2000],\n",
    "    },\n",
    "]\n",
    "\n",
    "results = []\n",
    "for k in range(5, 55):\n",
    "    print(f\"\\n=== Testing top {k} features ===\")\n",
    "    top_feats = ranking.head(k).index.tolist()\n",
    "    X_train_sel = X_train[top_feats]\n",
    "    X_test_sel = X_test[top_feats]\n",
    "\n",
    "    base = SVC(probability=True, random_state=42, cache_size=1000.0)\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=base,\n",
    "        param_distributions=search_spaces,  # list of dicts => supports conditionals\n",
    "        n_iter=80,\n",
    "        scoring=\"roc_auc\",  # align search with AUC\n",
    "        cv=3,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=0,\n",
    "        error_score=\"raise\",\n",
    "    )\n",
    "\n",
    "    search.fit(X_train_sel, y_train)\n",
    "\n",
    "    best_model = search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test_sel)\n",
    "    y_prob = best_model.predict_proba(X_test_sel)[:, 1]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    results.append((k, acc, auc))\n",
    "\n",
    "    print(f\"Best parameters: {search.best_params_}\")\n",
    "    print(f\"Accuracy: {acc:.3f} | ROC-AUC: {auc:.3f}\")\n",
    "\n",
    "# Analyze\n",
    "results = np.array(results, dtype=float)\n",
    "feature_counts = results[:, 0]\n",
    "accuracies = results[:, 1]\n",
    "auc_scores = results[:, 2]\n",
    "\n",
    "best_index = np.argmax(accuracies)\n",
    "best_k = int(feature_counts[best_index])\n",
    "best_acc = accuracies[best_index]\n",
    "best_auc = auc_scores[best_index]\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(feature_counts, accuracies, \"o-\", label=\"Accuracy\")\n",
    "plt.plot(feature_counts, auc_scores, \"s--\", label=\"ROC-AUC\")\n",
    "plt.scatter(\n",
    "    best_k, best_acc, s=100, zorder=5, label=f\"Accuracy={best_acc:.3f}/k={best_k}\"\n",
    ")\n",
    "plt.title(\"SVM performance\")\n",
    "plt.xlabel(\"Number of selected features\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAccuracy = {best_acc:.3f} | ROC-AUC = {best_auc:.3f} | k = {best_k}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
